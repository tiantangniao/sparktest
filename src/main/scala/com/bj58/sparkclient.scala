package com.bj58

import org.apache.spark.SparkConf
import org.apache.spark.streaming.dstream.{PreReduceWindowDStream, PreWindowDStream}
import org.apache.spark.streaming.{Seconds, StreamingContext}

/**
  * Created by 58 on 2016/11/20.
  */
object sparkclient {
  def main(args: Array[String]) {

    val sparkConf = new SparkConf().setMaster("local[2]").setAppName("sparkstudy")
    val ssc = new StreamingContext(sparkConf, Seconds(1))

    // Create a socket stream on target ip:port and count the
    // words in input stream of \n delimited text (eg. generated by 'nc')
    // Note that no duplication in storage level only for running locally.
    // Replication necessary in distributed scenario for fault tolerance.
    val lines = ssc.socketTextStream("127.0.0.1", 9999)

    val dance1 = lines.flatMap(_.split("w"))

    val sidgrouplines=dance1.map(value =>{
      if(value.startsWith("#")){
        (value.substring(1),value.substring(1)+"pre")
      }else{
        (value.substring(1),value.substring(1)+"hou")
      }
    })
    //sidgroupline
    println("???????????????????????????????????????????????????????")
    println(System.currentTimeMillis())
    val ceshio=System.currentTimeMillis()


    //val midlledetail=sidgrouplines.reduceByKeyAndWindow((c1:String,c2:String)=>c1+"??"+c2, Seconds(12),Seconds(1)).map(line=>line._2)
    //val dance3=new  PreReduceWindowDStream(sidgrouplines, (c1:String,c2:String)=>c1+"??"+c2,Seconds(12), Seconds(1))
    //val dance3=new  PreWindowDStream(sidgrouplines, Seconds(12), Seconds(1))


   // dance3.foreachRDD(rdd => println("#########"+rdd.count()))
    //PreWindowDStream


    ssc.checkpoint("/home/hdp_lbg_ectech/middata/dingxiao/spark/checkpoint/")

    ssc.start()
    ssc.awaitTermination()
  }
}
